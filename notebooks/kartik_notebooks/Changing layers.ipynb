{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08f4af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops, math_ops      #for math operations division_no_nan\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "\n",
    "import hls4ml\n",
    "from hls4ml.model.profiling import numerical, activations_keras, boxplot\n",
    "\n",
    "sys.path.append('/usersc/bz18310/previous_notebook/cms-l1-triggers')\n",
    "\n",
    "from utils.analysis import eff_rate, optimal_eff_rate\n",
    "from utils.preprocessing import resize\n",
    "from utils.plotting import *\n",
    "from utils.hls4ml_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a2322",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "1) Number of parameters increases when second conv layer removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa3916d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(in_shape, second_layer=True):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(Conv2D(4, kernel_size=(3,3), input_shape=in_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    if second_layer:\n",
    "        model.add(Conv2D(8, kernel_size=(3,3)))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "        model.add(BatchNormalization(axis=1))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(24))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.build(input_shape=in_shape)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    model = compiler(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compiler(model_name):\n",
    "    opt = tf.keras.optimizers.Adam(0.001)\n",
    "    sensitivity_metric = tf.keras.metrics.SensitivityAtSpecificity(name='sens_at_spec',\n",
    "                                                                             specificity=0.99925,     \n",
    "                                                                             num_thresholds=20000)     \n",
    "    auc_metric = tf.keras.metrics.AUC(name='auc', num_thresholds=200)   \n",
    "    metrics = ['accuracy', sensitivity_metric, auc_metric]\n",
    "\n",
    "    model_name.compile(optimizer=opt, loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    return model_name\n",
    "\n",
    "def trainer(model_name, train_X, train_y):     \n",
    "\n",
    "    model_name.fit(train_X, \n",
    "               train_y, \n",
    "               epochs=50, \n",
    "               verbose=1,\n",
    "               batch_size=512, \n",
    "               validation_split=.2,   \n",
    "               shuffle=True,\n",
    "               callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                             patience=5,\n",
    "                                                             restore_best_weights=True),     \n",
    "                            pruning_callbacks.UpdatePruningStep()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5568d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coarse model data 20x12\n",
    "data = np.load('./data_hh4b_20x12_160000.npz')\n",
    "train_X_c = data['train_X']      #data for training the quantized model\n",
    "train_y_c = data['train_y']      #data labels\n",
    "test_X_c = data['test_X']\n",
    "test_y_c = data['test_y']\n",
    "data = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0e47f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#120x12 fine model data\n",
    "train_X = np.load('/storage1/bz18310/hist_data/train_test_120x72/train_X.npy')\n",
    "train_y = np.load('/storage1/bz18310/hist_data/train_test_120x72/train_y.npy')\n",
    "test_X = np.load('/storage1/bz18310/hist_data/train_test_120x72/test_X.npy')\n",
    "test_y = np.load('/storage1/bz18310/hist_data/train_test_120x72/test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8232b7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 118, 70, 4)        40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 59, 35, 4)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 59, 35, 4)         236       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 59, 35, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 57, 33, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 28, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 28, 16, 8)         112       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 28, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 24)                86040     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 86,849\n",
      "Trainable params: 86,625\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 118, 70, 4)        40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 59, 35, 4)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 59, 35, 4)         236       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 59, 35, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 8260)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 24)                198264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 198,665\n",
      "Trainable params: 198,497\n",
      "Non-trainable params: 168\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 18, 10, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 9, 5, 4)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 9, 5, 4)           36        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 9, 5, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 3, 8)           296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 3, 1, 8)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 3, 1, 8)           12        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 3, 1, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,109\n",
      "Trainable params: 1,035\n",
      "Non-trainable params: 74\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 18, 10, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 9, 5, 4)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 9, 5, 4)           36        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 9, 5, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 24)                4344      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,477\n",
      "Non-trainable params: 68\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_120_full = make_model((120,72,1), second_layer=True)\n",
    "model_120_half = make_model((120,72,1), second_layer=False)\n",
    "model_20_full = make_model((20,12,1), second_layer=True)\n",
    "model_20_half = make_model((20,12,1), second_layer=False)   #note the number parameters increases here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e198ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "442/442 [==============================] - 158s 355ms/step - loss: 0.3528 - accuracy: 0.9120 - sens_at_spec: 0.2088 - auc: 0.9922 - val_loss: 0.2980 - val_accuracy: 0.9638 - val_sens_at_spec: 0.3826 - val_auc: 0.9955\n",
      "Epoch 2/50\n",
      "442/442 [==============================] - 154s 349ms/step - loss: 0.2120 - accuracy: 0.9765 - sens_at_spec: 0.1089 - auc: 0.9949 - val_loss: 0.1745 - val_accuracy: 0.9784 - val_sens_at_spec: 0.0856 - val_auc: 0.9954\n",
      "Epoch 3/50\n",
      "442/442 [==============================] - 154s 349ms/step - loss: 0.1516 - accuracy: 0.9806 - sens_at_spec: 0.1926 - auc: 0.9955 - val_loss: 0.1326 - val_accuracy: 0.9799 - val_sens_at_spec: 0.0603 - val_auc: 0.9956\n",
      "Epoch 4/50\n",
      "442/442 [==============================] - 155s 351ms/step - loss: 0.1176 - accuracy: 0.9821 - sens_at_spec: 0.2755 - auc: 0.9962 - val_loss: 0.1071 - val_accuracy: 0.9817 - val_sens_at_spec: 0.0803 - val_auc: 0.9962\n",
      "Epoch 5/50\n",
      "442/442 [==============================] - 155s 352ms/step - loss: 0.0959 - accuracy: 0.9829 - sens_at_spec: 0.3240 - auc: 0.9968 - val_loss: 0.0889 - val_accuracy: 0.9826 - val_sens_at_spec: 0.0714 - val_auc: 0.9955\n",
      "Epoch 6/50\n",
      "442/442 [==============================] - 156s 352ms/step - loss: 0.0820 - accuracy: 0.9836 - sens_at_spec: 0.4936 - auc: 0.9973 - val_loss: 0.0796 - val_accuracy: 0.9812 - val_sens_at_spec: 0.2083 - val_auc: 0.9966\n",
      "Epoch 7/50\n",
      "442/442 [==============================] - 155s 351ms/step - loss: 0.0719 - accuracy: 0.9841 - sens_at_spec: 0.6419 - auc: 0.9976 - val_loss: 0.0920 - val_accuracy: 0.9785 - val_sens_at_spec: 0.0365 - val_auc: 0.9954\n",
      "Epoch 8/50\n",
      "442/442 [==============================] - 155s 351ms/step - loss: 0.0642 - accuracy: 0.9846 - sens_at_spec: 0.7346 - auc: 0.9978 - val_loss: 0.0670 - val_accuracy: 0.9836 - val_sens_at_spec: 0.1857 - val_auc: 0.9967\n",
      "Epoch 9/50\n",
      "442/442 [==============================] - 156s 353ms/step - loss: 0.0588 - accuracy: 0.9851 - sens_at_spec: 0.7508 - auc: 0.9979 - val_loss: 0.0637 - val_accuracy: 0.9818 - val_sens_at_spec: 0.6368 - val_auc: 0.9970\n",
      "Epoch 10/50\n",
      "442/442 [==============================] - 155s 352ms/step - loss: 0.0545 - accuracy: 0.9850 - sens_at_spec: 0.8335 - auc: 0.9981 - val_loss: 0.0584 - val_accuracy: 0.9834 - val_sens_at_spec: 0.5032 - val_auc: 0.9968\n",
      "Epoch 11/50\n",
      "442/442 [==============================] - 155s 351ms/step - loss: 0.0508 - accuracy: 0.9856 - sens_at_spec: 0.8517 - auc: 0.9982 - val_loss: 0.0781 - val_accuracy: 0.9770 - val_sens_at_spec: 0.1397 - val_auc: 0.9959\n",
      "Epoch 12/50\n",
      "442/442 [==============================] - 156s 353ms/step - loss: 0.0482 - accuracy: 0.9856 - sens_at_spec: 0.8611 - auc: 0.9983 - val_loss: 0.0560 - val_accuracy: 0.9829 - val_sens_at_spec: 0.2774 - val_auc: 0.9969\n",
      "Epoch 13/50\n",
      "442/442 [==============================] - 157s 356ms/step - loss: 0.0458 - accuracy: 0.9859 - sens_at_spec: 0.8800 - auc: 0.9984 - val_loss: 0.0575 - val_accuracy: 0.9822 - val_sens_at_spec: 0.1162 - val_auc: 0.9961\n",
      "Epoch 14/50\n",
      "442/442 [==============================] - 158s 357ms/step - loss: 0.0434 - accuracy: 0.9864 - sens_at_spec: 0.8869 - auc: 0.9984 - val_loss: 0.0587 - val_accuracy: 0.9821 - val_sens_at_spec: 0.6449 - val_auc: 0.9967\n",
      "Epoch 15/50\n",
      "442/442 [==============================] - 158s 357ms/step - loss: 0.0414 - accuracy: 0.9869 - sens_at_spec: 0.9025 - auc: 0.9985 - val_loss: 0.0547 - val_accuracy: 0.9831 - val_sens_at_spec: 0.1456 - val_auc: 0.9961\n",
      "Epoch 16/50\n",
      "442/442 [==============================] - 161s 365ms/step - loss: 0.0398 - accuracy: 0.9870 - sens_at_spec: 0.9190 - auc: 0.9987 - val_loss: 0.0531 - val_accuracy: 0.9831 - val_sens_at_spec: 0.2926 - val_auc: 0.9966\n",
      "Epoch 17/50\n",
      "442/442 [==============================] - 160s 362ms/step - loss: 0.0386 - accuracy: 0.9873 - sens_at_spec: 0.9227 - auc: 0.9987 - val_loss: 0.0665 - val_accuracy: 0.9785 - val_sens_at_spec: 0.0705 - val_auc: 0.9959\n",
      "Epoch 18/50\n",
      "442/442 [==============================] - 158s 357ms/step - loss: 0.0372 - accuracy: 0.9877 - sens_at_spec: 0.9279 - auc: 0.9987 - val_loss: 0.0553 - val_accuracy: 0.9828 - val_sens_at_spec: 0.1140 - val_auc: 0.9964\n",
      "Epoch 19/50\n",
      "442/442 [==============================] - 158s 358ms/step - loss: 0.0358 - accuracy: 0.9879 - sens_at_spec: 0.9341 - auc: 0.9988 - val_loss: 0.0891 - val_accuracy: 0.9704 - val_sens_at_spec: 0.0380 - val_auc: 0.9948\n",
      "Epoch 20/50\n",
      "442/442 [==============================] - 156s 354ms/step - loss: 0.0348 - accuracy: 0.9884 - sens_at_spec: 0.9387 - auc: 0.9988 - val_loss: 0.0599 - val_accuracy: 0.9805 - val_sens_at_spec: 0.2039 - val_auc: 0.9953\n",
      "Epoch 21/50\n",
      "442/442 [==============================] - 157s 355ms/step - loss: 0.0337 - accuracy: 0.9886 - sens_at_spec: 0.9460 - auc: 0.9988 - val_loss: 0.0538 - val_accuracy: 0.9832 - val_sens_at_spec: 0.2692 - val_auc: 0.9961\n",
      "Epoch 1/50\n",
      "442/442 [==============================] - 176s 392ms/step - loss: 0.3548 - accuracy: 0.9116 - sens_at_spec: 0.0979 - auc: 0.9918 - val_loss: 0.2948 - val_accuracy: 0.9794 - val_sens_at_spec: 0.0124 - val_auc: 0.9946\n",
      "Epoch 2/50\n",
      "442/442 [==============================] - 131s 293ms/step - loss: 0.2119 - accuracy: 0.9779 - sens_at_spec: 0.0876 - auc: 0.9949 - val_loss: 0.1824 - val_accuracy: 0.9822 - val_sens_at_spec: 0.0873 - val_auc: 0.9955\n",
      "Epoch 3/50\n",
      "442/442 [==============================] - 141s 319ms/step - loss: 0.1498 - accuracy: 0.9823 - sens_at_spec: 0.2481 - auc: 0.9962 - val_loss: 0.1306 - val_accuracy: 0.9827 - val_sens_at_spec: 0.0331 - val_auc: 0.9947\n",
      "Epoch 4/50\n",
      "442/442 [==============================] - 128s 287ms/step - loss: 0.1154 - accuracy: 0.9834 - sens_at_spec: 0.2502 - auc: 0.9969 - val_loss: 0.1074 - val_accuracy: 0.9833 - val_sens_at_spec: 0.0452 - val_auc: 0.9951\n",
      "Epoch 5/50\n",
      "442/442 [==============================] - 123s 279ms/step - loss: 0.0940 - accuracy: 0.9837 - sens_at_spec: 0.4999 - auc: 0.9975 - val_loss: 0.0922 - val_accuracy: 0.9829 - val_sens_at_spec: 0.0667 - val_auc: 0.9961\n",
      "Epoch 6/50\n",
      "442/442 [==============================] - 123s 278ms/step - loss: 0.0790 - accuracy: 0.9848 - sens_at_spec: 0.6977 - auc: 0.9979 - val_loss: 0.0869 - val_accuracy: 0.9820 - val_sens_at_spec: 0.0494 - val_auc: 0.9953\n",
      "Epoch 7/50\n",
      "442/442 [==============================] - 122s 276ms/step - loss: 0.0681 - accuracy: 0.9855 - sens_at_spec: 0.8387 - auc: 0.9982 - val_loss: 0.0811 - val_accuracy: 0.9815 - val_sens_at_spec: 0.0085 - val_auc: 0.9940\n",
      "Epoch 8/50\n",
      "442/442 [==============================] - 122s 277ms/step - loss: 0.0604 - accuracy: 0.9858 - sens_at_spec: 0.8668 - auc: 0.9984 - val_loss: 0.0668 - val_accuracy: 0.9829 - val_sens_at_spec: 0.0527 - val_auc: 0.9960\n",
      "Epoch 9/50\n",
      "442/442 [==============================] - 122s 275ms/step - loss: 0.0540 - accuracy: 0.9868 - sens_at_spec: 0.8977 - auc: 0.9986 - val_loss: 0.0636 - val_accuracy: 0.9824 - val_sens_at_spec: 0.0882 - val_auc: 0.9965\n",
      "Epoch 10/50\n",
      "442/442 [==============================] - 123s 278ms/step - loss: 0.0494 - accuracy: 0.9869 - sens_at_spec: 0.9053 - auc: 0.9986 - val_loss: 0.0633 - val_accuracy: 0.9817 - val_sens_at_spec: 0.0931 - val_auc: 0.9965\n",
      "Epoch 11/50\n",
      "442/442 [==============================] - 122s 277ms/step - loss: 0.0452 - accuracy: 0.9875 - sens_at_spec: 0.9279 - auc: 0.9988 - val_loss: 0.0580 - val_accuracy: 0.9830 - val_sens_at_spec: 0.0933 - val_auc: 0.9960\n",
      "Epoch 12/50\n",
      "442/442 [==============================] - 122s 277ms/step - loss: 0.0418 - accuracy: 0.9880 - sens_at_spec: 0.9327 - auc: 0.9988 - val_loss: 0.0685 - val_accuracy: 0.9795 - val_sens_at_spec: 0.0352 - val_auc: 0.9951\n",
      "Epoch 13/50\n",
      "442/442 [==============================] - 123s 279ms/step - loss: 0.0382 - accuracy: 0.9890 - sens_at_spec: 0.9452 - auc: 0.9990 - val_loss: 0.1225 - val_accuracy: 0.9609 - val_sens_at_spec: 0.0131 - val_auc: 0.9905\n",
      "Epoch 14/50\n",
      "442/442 [==============================] - 123s 278ms/step - loss: 0.0360 - accuracy: 0.9895 - sens_at_spec: 0.9470 - auc: 0.9990 - val_loss: 0.0603 - val_accuracy: 0.9815 - val_sens_at_spec: 0.0593 - val_auc: 0.9945\n",
      "Epoch 15/50\n",
      "442/442 [==============================] - 122s 275ms/step - loss: 0.0335 - accuracy: 0.9900 - sens_at_spec: 0.9588 - auc: 0.9991 - val_loss: 0.0582 - val_accuracy: 0.9825 - val_sens_at_spec: 0.0548 - val_auc: 0.9945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "442/442 [==============================] - 121s 275ms/step - loss: 0.0317 - accuracy: 0.9904 - sens_at_spec: 0.9587 - auc: 0.9991 - val_loss: 0.0648 - val_accuracy: 0.9798 - val_sens_at_spec: 0.0541 - val_auc: 0.9952\n",
      "Epoch 1/50\n",
      "188/188 [==============================] - 20s 63ms/step - loss: 0.3670 - accuracy: 0.9403 - sens_at_spec: 0.2998 - auc: 0.9872 - val_loss: 0.8925 - val_accuracy: 0.5021 - val_sens_at_spec: 0.5102 - val_auc: 0.9492\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.2817 - accuracy: 0.9676 - sens_at_spec: 0.1916 - auc: 0.9929 - val_loss: 0.8395 - val_accuracy: 0.5340 - val_sens_at_spec: 0.4646 - val_auc: 0.9500\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.2457 - accuracy: 0.9688 - sens_at_spec: 0.1782 - auc: 0.9926 - val_loss: 0.3210 - val_accuracy: 0.8923 - val_sens_at_spec: 0.5538 - val_auc: 0.9937\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.2193 - accuracy: 0.9697 - sens_at_spec: 0.1435 - auc: 0.9924 - val_loss: 0.2128 - val_accuracy: 0.9654 - val_sens_at_spec: 0.4605 - val_auc: 0.9946\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.1988 - accuracy: 0.9700 - sens_at_spec: 0.1442 - auc: 0.9926 - val_loss: 0.1993 - val_accuracy: 0.9679 - val_sens_at_spec: 0.1596 - val_auc: 0.9943\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 10s 56ms/step - loss: 0.1823 - accuracy: 0.9698 - sens_at_spec: 0.2107 - auc: 0.9929 - val_loss: 0.1709 - val_accuracy: 0.9684 - val_sens_at_spec: 0.5148 - val_auc: 0.9942\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.1680 - accuracy: 0.9706 - sens_at_spec: 0.2650 - auc: 0.9932 - val_loss: 0.1587 - val_accuracy: 0.9704 - val_sens_at_spec: 0.4915 - val_auc: 0.9946\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.1576 - accuracy: 0.9701 - sens_at_spec: 0.2265 - auc: 0.9929 - val_loss: 0.1510 - val_accuracy: 0.9707 - val_sens_at_spec: 0.4260 - val_auc: 0.9949\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.1465 - accuracy: 0.9708 - sens_at_spec: 0.2293 - auc: 0.9936 - val_loss: 0.1393 - val_accuracy: 0.9678 - val_sens_at_spec: 0.4901 - val_auc: 0.9949\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.1380 - accuracy: 0.9708 - sens_at_spec: 0.2829 - auc: 0.9938 - val_loss: 0.1379 - val_accuracy: 0.9707 - val_sens_at_spec: 0.1637 - val_auc: 0.9943\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.1319 - accuracy: 0.9709 - sens_at_spec: 0.2993 - auc: 0.9937 - val_loss: 0.1261 - val_accuracy: 0.9694 - val_sens_at_spec: 0.4345 - val_auc: 0.9951\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.1257 - accuracy: 0.9708 - sens_at_spec: 0.3126 - auc: 0.9940 - val_loss: 0.1206 - val_accuracy: 0.9707 - val_sens_at_spec: 0.3341 - val_auc: 0.9949\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.1208 - accuracy: 0.9711 - sens_at_spec: 0.3064 - auc: 0.9940 - val_loss: 0.1209 - val_accuracy: 0.9693 - val_sens_at_spec: 0.2174 - val_auc: 0.9947\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.1157 - accuracy: 0.9713 - sens_at_spec: 0.4239 - auc: 0.9943 - val_loss: 0.1225 - val_accuracy: 0.9700 - val_sens_at_spec: 0.5013 - val_auc: 0.9952\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.1120 - accuracy: 0.9711 - sens_at_spec: 0.3483 - auc: 0.9942 - val_loss: 0.1092 - val_accuracy: 0.9712 - val_sens_at_spec: 0.2717 - val_auc: 0.9949\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.1085 - accuracy: 0.9715 - sens_at_spec: 0.4596 - auc: 0.9944 - val_loss: 0.1034 - val_accuracy: 0.9704 - val_sens_at_spec: 0.5477 - val_auc: 0.9952\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.1061 - accuracy: 0.9709 - sens_at_spec: 0.4083 - auc: 0.9944 - val_loss: 0.1015 - val_accuracy: 0.9707 - val_sens_at_spec: 0.4634 - val_auc: 0.9951\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.1033 - accuracy: 0.9711 - sens_at_spec: 0.3752 - auc: 0.9944 - val_loss: 0.1000 - val_accuracy: 0.9702 - val_sens_at_spec: 0.5028 - val_auc: 0.9952\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.1012 - accuracy: 0.9714 - sens_at_spec: 0.4592 - auc: 0.9944 - val_loss: 0.0991 - val_accuracy: 0.9712 - val_sens_at_spec: 0.4835 - val_auc: 0.9953\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0987 - accuracy: 0.9718 - sens_at_spec: 0.4230 - auc: 0.9946 - val_loss: 0.1001 - val_accuracy: 0.9705 - val_sens_at_spec: 0.4674 - val_auc: 0.9953\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0974 - accuracy: 0.9712 - sens_at_spec: 0.4273 - auc: 0.9945 - val_loss: 0.0937 - val_accuracy: 0.9708 - val_sens_at_spec: 0.5350 - val_auc: 0.9954\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0957 - accuracy: 0.9710 - sens_at_spec: 0.4533 - auc: 0.9946 - val_loss: 0.0927 - val_accuracy: 0.9709 - val_sens_at_spec: 0.5719 - val_auc: 0.9953\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0934 - accuracy: 0.9715 - sens_at_spec: 0.5150 - auc: 0.9947 - val_loss: 0.0926 - val_accuracy: 0.9710 - val_sens_at_spec: 0.5138 - val_auc: 0.9953\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0925 - accuracy: 0.9714 - sens_at_spec: 0.4780 - auc: 0.9946 - val_loss: 0.1791 - val_accuracy: 0.9423 - val_sens_at_spec: 0.3373 - val_auc: 0.9947\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0910 - accuracy: 0.9717 - sens_at_spec: 0.4655 - auc: 0.9948 - val_loss: 0.0885 - val_accuracy: 0.9707 - val_sens_at_spec: 0.5094 - val_auc: 0.9954\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0901 - accuracy: 0.9717 - sens_at_spec: 0.4371 - auc: 0.9947 - val_loss: 0.0896 - val_accuracy: 0.9710 - val_sens_at_spec: 0.5658 - val_auc: 0.9954\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0887 - accuracy: 0.9719 - sens_at_spec: 0.5473 - auc: 0.9948 - val_loss: 0.0915 - val_accuracy: 0.9694 - val_sens_at_spec: 0.5352 - val_auc: 0.9954\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0881 - accuracy: 0.9719 - sens_at_spec: 0.5762 - auc: 0.9949 - val_loss: 0.1057 - val_accuracy: 0.9630 - val_sens_at_spec: 0.5989 - val_auc: 0.9954\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0875 - accuracy: 0.9719 - sens_at_spec: 0.5825 - auc: 0.9949 - val_loss: 0.1234 - val_accuracy: 0.9564 - val_sens_at_spec: 0.5841 - val_auc: 0.9951\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0868 - accuracy: 0.9719 - sens_at_spec: 0.5192 - auc: 0.9948 - val_loss: 0.0905 - val_accuracy: 0.9703 - val_sens_at_spec: 0.5762 - val_auc: 0.9954\n",
      "Epoch 1/50\n",
      "188/188 [==============================] - 11s 53ms/step - loss: 0.3839 - accuracy: 0.9355 - sens_at_spec: 0.2926 - auc: 0.9825 - val_loss: 1.4620 - val_accuracy: 0.5004 - val_sens_at_spec: 0.5542 - val_auc: 0.9801\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.2847 - accuracy: 0.9716 - sens_at_spec: 0.3296 - auc: 0.9949 - val_loss: 1.2183 - val_accuracy: 0.5129 - val_sens_at_spec: 0.5461 - val_auc: 0.9939\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.2466 - accuracy: 0.9736 - sens_at_spec: 0.3530 - auc: 0.9954 - val_loss: 0.4580 - val_accuracy: 0.7503 - val_sens_at_spec: 0.5701 - val_auc: 0.9960\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 10s 56ms/step - loss: 0.2179 - accuracy: 0.9745 - sens_at_spec: 0.3528 - auc: 0.9955 - val_loss: 0.2055 - val_accuracy: 0.9582 - val_sens_at_spec: 0.5221 - val_auc: 0.9964\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.1949 - accuracy: 0.9749 - sens_at_spec: 0.3170 - auc: 0.9954 - val_loss: 0.1728 - val_accuracy: 0.9721 - val_sens_at_spec: 0.5074 - val_auc: 0.9965\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 10s 54ms/step - loss: 0.1770 - accuracy: 0.9751 - sens_at_spec: 0.3592 - auc: 0.9955 - val_loss: 0.1593 - val_accuracy: 0.9763 - val_sens_at_spec: 0.4301 - val_auc: 0.9963\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.1620 - accuracy: 0.9755 - sens_at_spec: 0.3613 - auc: 0.9955 - val_loss: 0.1457 - val_accuracy: 0.9753 - val_sens_at_spec: 0.5682 - val_auc: 0.9964\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.1496 - accuracy: 0.9752 - sens_at_spec: 0.3558 - auc: 0.9957 - val_loss: 0.1403 - val_accuracy: 0.9768 - val_sens_at_spec: 0.5367 - val_auc: 0.9965\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.1390 - accuracy: 0.9759 - sens_at_spec: 0.4812 - auc: 0.9959 - val_loss: 0.1590 - val_accuracy: 0.9751 - val_sens_at_spec: 0.5793 - val_auc: 0.9965\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.1306 - accuracy: 0.9753 - sens_at_spec: 0.4225 - auc: 0.9958 - val_loss: 0.1331 - val_accuracy: 0.9762 - val_sens_at_spec: 0.5974 - val_auc: 0.9966\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.1228 - accuracy: 0.9757 - sens_at_spec: 0.5016 - auc: 0.9960 - val_loss: 0.1096 - val_accuracy: 0.9772 - val_sens_at_spec: 0.5679 - val_auc: 0.9966\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.1166 - accuracy: 0.9758 - sens_at_spec: 0.5177 - auc: 0.9961 - val_loss: 0.1111 - val_accuracy: 0.9775 - val_sens_at_spec: 0.5427 - val_auc: 0.9966\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.1106 - accuracy: 0.9759 - sens_at_spec: 0.5205 - auc: 0.9962 - val_loss: 0.1036 - val_accuracy: 0.9769 - val_sens_at_spec: 0.6453 - val_auc: 0.9966\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.1050 - accuracy: 0.9763 - sens_at_spec: 0.6103 - auc: 0.9964 - val_loss: 0.1042 - val_accuracy: 0.9766 - val_sens_at_spec: 0.5840 - val_auc: 0.9966\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.1013 - accuracy: 0.9762 - sens_at_spec: 0.5633 - auc: 0.9963 - val_loss: 0.0951 - val_accuracy: 0.9775 - val_sens_at_spec: 0.5744 - val_auc: 0.9967\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0969 - accuracy: 0.9767 - sens_at_spec: 0.6139 - auc: 0.9964 - val_loss: 0.0964 - val_accuracy: 0.9771 - val_sens_at_spec: 0.6225 - val_auc: 0.9966\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0935 - accuracy: 0.9766 - sens_at_spec: 0.6356 - auc: 0.9964 - val_loss: 0.0904 - val_accuracy: 0.9772 - val_sens_at_spec: 0.6291 - val_auc: 0.9966\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0908 - accuracy: 0.9765 - sens_at_spec: 0.6299 - auc: 0.9964 - val_loss: 0.0910 - val_accuracy: 0.9767 - val_sens_at_spec: 0.6453 - val_auc: 0.9966\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0881 - accuracy: 0.9764 - sens_at_spec: 0.6714 - auc: 0.9965 - val_loss: 0.0866 - val_accuracy: 0.9768 - val_sens_at_spec: 0.6379 - val_auc: 0.9966\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0851 - accuracy: 0.9771 - sens_at_spec: 0.6437 - auc: 0.9966 - val_loss: 0.0912 - val_accuracy: 0.9770 - val_sens_at_spec: 0.6488 - val_auc: 0.9967\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0832 - accuracy: 0.9768 - sens_at_spec: 0.6686 - auc: 0.9966 - val_loss: 0.0885 - val_accuracy: 0.9771 - val_sens_at_spec: 0.6612 - val_auc: 0.9967\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0812 - accuracy: 0.9771 - sens_at_spec: 0.6757 - auc: 0.9966 - val_loss: 0.0795 - val_accuracy: 0.9761 - val_sens_at_spec: 0.6442 - val_auc: 0.9967\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0787 - accuracy: 0.9773 - sens_at_spec: 0.6761 - auc: 0.9967 - val_loss: 0.0872 - val_accuracy: 0.9773 - val_sens_at_spec: 0.5580 - val_auc: 0.9964\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0775 - accuracy: 0.9771 - sens_at_spec: 0.7193 - auc: 0.9967 - val_loss: 0.0799 - val_accuracy: 0.9769 - val_sens_at_spec: 0.6324 - val_auc: 0.9966\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0758 - accuracy: 0.9773 - sens_at_spec: 0.7210 - auc: 0.9968 - val_loss: 0.0778 - val_accuracy: 0.9770 - val_sens_at_spec: 0.6264 - val_auc: 0.9966\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0744 - accuracy: 0.9773 - sens_at_spec: 0.6896 - auc: 0.9968 - val_loss: 0.0831 - val_accuracy: 0.9725 - val_sens_at_spec: 0.6049 - val_auc: 0.9964\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0734 - accuracy: 0.9772 - sens_at_spec: 0.7227 - auc: 0.9969 - val_loss: 0.0788 - val_accuracy: 0.9750 - val_sens_at_spec: 0.5764 - val_auc: 0.9964\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0722 - accuracy: 0.9779 - sens_at_spec: 0.7230 - auc: 0.9968 - val_loss: 0.0762 - val_accuracy: 0.9779 - val_sens_at_spec: 0.5754 - val_auc: 0.9964\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0707 - accuracy: 0.9782 - sens_at_spec: 0.7192 - auc: 0.9969 - val_loss: 0.0744 - val_accuracy: 0.9779 - val_sens_at_spec: 0.5975 - val_auc: 0.9965\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0703 - accuracy: 0.9777 - sens_at_spec: 0.7327 - auc: 0.9969 - val_loss: 0.1318 - val_accuracy: 0.9587 - val_sens_at_spec: 0.6035 - val_auc: 0.9964\n",
      "Epoch 31/50\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0693 - accuracy: 0.9777 - sens_at_spec: 0.7322 - auc: 0.9969 - val_loss: 0.0971 - val_accuracy: 0.9728 - val_sens_at_spec: 0.6020 - val_auc: 0.9962\n",
      "Epoch 32/50\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0682 - accuracy: 0.9781 - sens_at_spec: 0.7630 - auc: 0.9970 - val_loss: 0.0760 - val_accuracy: 0.9758 - val_sens_at_spec: 0.5068 - val_auc: 0.9963\n",
      "Epoch 33/50\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0678 - accuracy: 0.9781 - sens_at_spec: 0.7336 - auc: 0.9969 - val_loss: 0.1163 - val_accuracy: 0.9646 - val_sens_at_spec: 0.5661 - val_auc: 0.9963\n",
      "Epoch 34/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0664 - accuracy: 0.9784 - sens_at_spec: 0.7552 - auc: 0.9971 - val_loss: 0.0705 - val_accuracy: 0.9780 - val_sens_at_spec: 0.5051 - val_auc: 0.9964\n",
      "Epoch 35/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0660 - accuracy: 0.9785 - sens_at_spec: 0.7719 - auc: 0.9970 - val_loss: 0.0715 - val_accuracy: 0.9767 - val_sens_at_spec: 0.5763 - val_auc: 0.9965\n",
      "Epoch 36/50\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0650 - accuracy: 0.9789 - sens_at_spec: 0.7399 - auc: 0.9971 - val_loss: 0.0730 - val_accuracy: 0.9770 - val_sens_at_spec: 0.5705 - val_auc: 0.9964\n",
      "Epoch 37/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0647 - accuracy: 0.9784 - sens_at_spec: 0.7839 - auc: 0.9971 - val_loss: 0.0728 - val_accuracy: 0.9772 - val_sens_at_spec: 0.5662 - val_auc: 0.9963\n",
      "Epoch 38/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0648 - accuracy: 0.9783 - sens_at_spec: 0.7609 - auc: 0.9970 - val_loss: 0.0733 - val_accuracy: 0.9762 - val_sens_at_spec: 0.6030 - val_auc: 0.9965\n",
      "Epoch 39/50\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0635 - accuracy: 0.9790 - sens_at_spec: 0.7527 - auc: 0.9972 - val_loss: 0.0693 - val_accuracy: 0.9764 - val_sens_at_spec: 0.6773 - val_auc: 0.9966\n",
      "Epoch 40/50\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0628 - accuracy: 0.9789 - sens_at_spec: 0.7936 - auc: 0.9973 - val_loss: 0.0713 - val_accuracy: 0.9774 - val_sens_at_spec: 0.5265 - val_auc: 0.9962\n",
      "Epoch 41/50\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0625 - accuracy: 0.9793 - sens_at_spec: 0.7926 - auc: 0.9972 - val_loss: 0.0693 - val_accuracy: 0.9772 - val_sens_at_spec: 0.5609 - val_auc: 0.9964\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0619 - accuracy: 0.9790 - sens_at_spec: 0.7909 - auc: 0.9972 - val_loss: 0.0703 - val_accuracy: 0.9767 - val_sens_at_spec: 0.5968 - val_auc: 0.9963\n",
      "Epoch 43/50\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0619 - accuracy: 0.9792 - sens_at_spec: 0.7944 - auc: 0.9972 - val_loss: 0.0682 - val_accuracy: 0.9774 - val_sens_at_spec: 0.6479 - val_auc: 0.9964\n",
      "Epoch 44/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0613 - accuracy: 0.9791 - sens_at_spec: 0.7704 - auc: 0.9973 - val_loss: 0.0730 - val_accuracy: 0.9756 - val_sens_at_spec: 0.5834 - val_auc: 0.9962\n",
      "Epoch 45/50\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0614 - accuracy: 0.9790 - sens_at_spec: 0.7751 - auc: 0.9972 - val_loss: 0.0677 - val_accuracy: 0.9777 - val_sens_at_spec: 0.6230 - val_auc: 0.9965\n",
      "Epoch 46/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0609 - accuracy: 0.9792 - sens_at_spec: 0.7957 - auc: 0.9973 - val_loss: 0.0689 - val_accuracy: 0.9770 - val_sens_at_spec: 0.6012 - val_auc: 0.9963\n",
      "Epoch 47/50\n",
      "188/188 [==============================] - 10s 56ms/step - loss: 0.0604 - accuracy: 0.9797 - sens_at_spec: 0.8088 - auc: 0.9973 - val_loss: 0.0719 - val_accuracy: 0.9766 - val_sens_at_spec: 0.5754 - val_auc: 0.9961\n",
      "Epoch 48/50\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0597 - accuracy: 0.9796 - sens_at_spec: 0.7957 - auc: 0.9973 - val_loss: 0.0986 - val_accuracy: 0.9674 - val_sens_at_spec: 0.5899 - val_auc: 0.9945\n",
      "Epoch 49/50\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0595 - accuracy: 0.9799 - sens_at_spec: 0.7991 - auc: 0.9974 - val_loss: 0.1317 - val_accuracy: 0.9577 - val_sens_at_spec: 0.6337 - val_auc: 0.9954\n",
      "Epoch 50/50\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0599 - accuracy: 0.9795 - sens_at_spec: 0.7902 - auc: 0.9973 - val_loss: 0.1260 - val_accuracy: 0.9605 - val_sens_at_spec: 0.6031 - val_auc: 0.9955\n"
     ]
    }
   ],
   "source": [
    "trainer(model_120_full, train_X, train_y)\n",
    "trainer(model_120_half, train_X, train_y)\n",
    "trainer(model_20_full, train_X_c, train_y_c)\n",
    "trainer(model_20_half, train_X_c, train_y_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f1ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "push = lambda x: x > .5       #function to check if number greater than .5\n",
    "\n",
    "def hls_model_accuracy(hls_model, test_X, test_y):                              #function for testing accurcry of hls model\n",
    "    return accuracy_score(test_y, [push(i) for i in hls_model.predict(test_X)])\n",
    "\n",
    "def get_timing(build_result):\n",
    "    return (build_result['BestLatency'], build_result['WorstLatency'],\n",
    "            build_result['IntervalMin'], build_result['IntervalMax'])\n",
    "\n",
    "\n",
    "class CustomSensitivityAtSpecificity(tf.keras.metrics.SensitivityAtSpecificity):     #specificity TN/(TN+FP) \n",
    "                                                                                \n",
    "    def __init__(self, specificity, num_thresholds=200, name=None, dtype=None):\n",
    "        if specificity < 0 or specificity > 1:\n",
    "            raise ValueError('`specificity` must be in the range [0, 1].')\n",
    "        self.specificity = specificity\n",
    "        self.num_thresholds = num_thresholds\n",
    "        super().__init__(\n",
    "            specificity, num_thresholds=num_thresholds, name=name, dtype=dtype)  #from the tf.kera.metrics.SensitivityAtSpecificity\n",
    "                                                                                 #class, creates out object\n",
    "    def result(self):\n",
    "        specificities = math_ops.div_no_nan(\n",
    "        self.true_negatives, self.true_negatives + self.false_positives)   #from keras class super()\n",
    "        sensitivities = math_ops.div_no_nan(\n",
    "        self.true_positives, self.true_positives + self.false_negatives)   \n",
    "        return self._find_max_under_constraint(\n",
    "                    specificities, sensitivities, math_ops.greater_equal)  #What?\n",
    "\n",
    "    def get_threshold(self):\n",
    "        specificities = math_ops.div_no_nan(\n",
    "        self.true_negatives, self.true_negatives + self.false_positives)\n",
    "        \n",
    "        sensitivities = math_ops.div_no_nan(\n",
    "        self.true_positives, self.true_positives + self.false_negatives)    #Sensitivity TP/(TP+FN)\n",
    "        \n",
    "        specs_above_thresh = array_ops.where(math_ops.greater_equal(specificities, self.value))   #What?\n",
    "        \n",
    "        return math_ops.reduce_min(array_ops.gather(self.thresholds, specs_above_thresh)).numpy()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881b882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
